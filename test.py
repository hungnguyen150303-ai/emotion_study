import pandas as pd
import tempfile
import os
import librosa
import torch
from transformers import pipeline

# Khá»Ÿi táº¡o pipeline (chá»‰ Ä‘á»‹nh feature extractor Ä‘Ãºng cÃ¡ch)
transcriber = pipeline(
    "automatic-speech-recognition",
    model="vinai/PhoWhisper-base",
    feature_extractor="vinai/PhoWhisper-base",
    tokenizer="vinai/PhoWhisper-base",
    device=0 if torch.cuda.is_available() else -1
)

# Äá»c file .parquet
df = pd.read_parquet("train-00000-of-00001.parquet")
print(f"ğŸ—‚ï¸ ÄÃ£ load {len(df)} dÃ²ng tá»« file .parquet")

transcripts = []

for idx, row in df.iterrows():
    path_info = row['path']
    tmp_file_path = None

    try:
        if isinstance(path_info, dict) and 'bytes' in path_info:
            audio_bytes = bytes(path_info['bytes'])

            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
                tmp_file.write(audio_bytes)
                tmp_file_path = tmp_file.name
        else:
            print(f"[{idx}] âŒ Dá»¯ liá»‡u audio khÃ´ng há»£p lá»‡")
            transcripts.append("ERROR: invalid audio format")
            continue

        # Load audio thÃ nh numpy
        audio, sr = librosa.load(tmp_file_path, sr=16000)

        # ğŸ§ Dá»± Ä‘oÃ¡n transcript (KHÃ”NG truyá»n sampling_rate)
        result = transcriber(audio)
        transcript = result['text']

        print(f"[{idx}] âœ… Transcript: {transcript[:50]}...")

    except Exception as e:
        transcript = f"ERROR: {e}"
        print(f"[{idx}] âŒ Lá»—i xá»­ lÃ½ audio: {e}")

    finally:
        if tmp_file_path and os.path.exists(tmp_file_path):
            os.remove(tmp_file_path)

        transcripts.append(transcript)

# Gáº¯n transcript vÃ o DataFrame vÃ  lÆ°u
df["transcript"] = transcripts
df.to_csv("pho_whisper_transcript.csv", index=False)
df.to_parquet("pho_whisper_transcript.parquet")

print("ğŸ“ ÄÃ£ lÆ°u transcript tiáº¿ng Viá»‡t vÃ o 'pho_whisper_transcript.csv'")

